import os
import streamlit as st
import pickle
import time
from dotenv import load_dotenv
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import UnstructuredURLLoader
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_openai import ChatOpenAI

load_dotenv() 

st.set_page_config(
    page_title="IntelliNews Analytics",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)
st.markdown("""
<style>
    .main-header {
        text-align: center;
        color: #2E86AB;
        font-size: 3rem;
        margin-bottom: 1rem;
    }
    .sub-header {
        text-align: center;
        color: #F24236;
        font-size: 1.2rem;
        margin-bottom: 2rem;
    }
    .sidebar-header {
        color: #2E86AB;
        font-weight: bold;
    }
    .status-message {
        padding: 10px;
        border-radius: 5px;
        margin: 10px 0;
    }
    .success {
        background-color: #d4edda;
        color: #155724;
    }
    .info {
        background-color: #d1ecf1;
        color: #0c5460;
    }
</style>
""", unsafe_allow_html=True)

st.markdown('<h1 class="main-header">üìä IntelliNews Analytics</h1>', unsafe_allow_html=True)
st.markdown('<p class="sub-header">Advanced News Research & Analysis Platform</p>', unsafe_allow_html=True)

st.sidebar.markdown('<h2 class="sidebar-header">üì∞ Article Sources</h2>', unsafe_allow_html=True)
st.sidebar.markdown("Enter up to 3 news article URLs for comprehensive analysis")

urls = []
for i in range(3):
    url = st.sidebar.text_input(
        f"üîó Article URL {i+1}", 
        placeholder=f"Enter news article URL {i+1}...",
        help="Paste the full URL of a news article"
    )
    urls.append(url)

st.sidebar.markdown("---")
process_url_clicked = st.sidebar.button(
    "üöÄ Analyze Articles", 
    type="primary",
    help="Click to process and analyze the provided URLs"
)

VECTOR_STORE_PATH = "faiss_store_openai.pkl"
main_content_area = st.empty()

@st.cache_resource
def initialize_llm():
    """Initialize and cache the language model for efficient usage."""
    api_key = os.getenv("GROQ_API_KEY")
    if not api_key:
        st.error("‚ö†Ô∏è GROQ_API_KEY not found in environment variables. Please check your .env file.")
        st.stop()
    
    return ChatOpenAI(
        api_key=api_key,
        base_url="https://api.groq.com/openai/v1",
        model="llama-3.3-70b-versatile"
    )

llm = initialize_llm()

if process_url_clicked:
    valid_urls = [url for url in urls if url.strip()]
    
    if not valid_urls:
        st.error("‚ö†Ô∏è Please provide at least one valid URL to proceed.")
    else:
        progress_container = st.container()
        
        with progress_container:
            st.success(f"üéØ Processing {len(valid_urls)} article(s)...")
            
            with st.spinner("üì• Loading article content..."):
                loader = UnstructuredURLLoader(urls=valid_urls)
                st.info("‚úÖ Article data successfully loaded")
                article_data = loader.load()
            
            with st.spinner("üìù Processing and chunking text..."):
                text_splitter = RecursiveCharacterTextSplitter(
                    separators=['\n\n', '\n', '.', ','],
                    chunk_size=1000
                )
                st.info("‚úÖ Text processing completed")
                processed_documents = text_splitter.split_documents(article_data)
            
            with st.spinner("üß† Creating knowledge embeddings..."):
                model_name = "all-MiniLM-L6-v2"
                embeddings = HuggingFaceEmbeddings(model_name=model_name)
                vector_store = FAISS.from_documents(processed_documents, embeddings)
                st.info("‚úÖ Knowledge base successfully created")
                time.sleep(1)

            with open(VECTOR_STORE_PATH, "wb") as f:
                pickle.dump(vector_store, f)
            
            st.success("üéâ Analysis complete! You can now ask questions about the articles.")

st.markdown("---")
st.markdown("### ü§î Ask Your Questions")
st.markdown("Enter your question about the analyzed articles and get instant insights.")

query = st.text_input(
    "üí≠ Your Question:", 
    placeholder="What are the key insights from these articles?",
    help="Ask any question about the content of the analyzed articles"
)

if query:
    if os.path.exists(VECTOR_STORE_PATH):
        with st.spinner("üîç Analyzing and generating response..."):
            with open(VECTOR_STORE_PATH, "rb") as f:
                loaded_vector_store = pickle.load(f)
                
                # Get relevant documents
                retriever = loaded_vector_store.as_retriever(search_kwargs={"k": 3})
                # relevant_docs = retriever.get_relevant_documents(query)
                relevant_docs = retriever.invoke(query)
                
                # Combine context from retrieved documents
                context = "\n\n".join([doc.page_content for doc in relevant_docs])
                
                # Create prompt for the LLM
                prompt = f"""Based on the following context from news articles, please answer the question.
                
Context:
{context}

Question: {query}

Answer:"""
                
                # Get response from LLM
                answer = llm.invoke(prompt).content
                
            col1, col2 = st.columns([2, 1])
            
            with col1:
                st.markdown("### üí° Analysis Result")
                st.markdown(f"**Question:** {query}")
                st.write(answer)
            
            with col2:
                if relevant_docs:
                    st.markdown("### üìö Source References")
                    sources_set = set()
                    for doc in relevant_docs:
                        source = doc.metadata.get('source', 'Unknown source')
                        sources_set.add(source)
                    
                    for idx, source in enumerate(sources_set, 1):
                        st.markdown(f"**{idx}.** {source}")
                else:
                    st.info("No specific sources identified for this response.")

    else:
        st.warning("‚ö†Ô∏è Please process some articles first before asking questions.")
        st.info("Use the sidebar to add article URLs and click 'Analyze Articles' to get started.")

st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #666; padding: 20px;'>
    <p><strong>IntelliNews Analytics</strong> - Powered by Advanced AI Technology</p>
    <p>üî¨ Analyze ‚Ä¢ üß† Understand ‚Ä¢ üìä Insights</p>
</div>
""", unsafe_allow_html=True)

st.sidebar.markdown("---")
st.sidebar.markdown("### ‚ÑπÔ∏è How to Use")
st.sidebar.markdown("""
1. **Add URLs**: Enter up to 3 news article URLs
2. **Analyze**: Click 'Analyze Articles' to process content
3. **Ask**: Type your questions about the articles
4. **Get Insights**: Receive AI-powered analysis with sources
""")

st.sidebar.markdown("### üîß Features")
st.sidebar.markdown("""
- ‚úÖ Multi-article analysis
- ‚úÖ Source attribution
- ‚úÖ Advanced AI processing
- ‚úÖ Real-time insights
""")

if os.path.exists(VECTOR_STORE_PATH):
    st.sidebar.success("üìä Knowledge base loaded and ready!")
else:
    st.sidebar.info("üîÑ Ready to analyze articles")




